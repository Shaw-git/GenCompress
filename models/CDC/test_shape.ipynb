{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f7ca26-076b-4488-afda-99480b099163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from utils import exists, LowerBound\n",
    "from einops import rearrange\n",
    "from utils import quantize, NormalDistribution\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.fn(x, *args, **kwargs) + x\n",
    "\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out=None, d3 = False):\n",
    "        super().__init__()\n",
    "        if dim_out is None:\n",
    "            dim_out = dim_in\n",
    "            \n",
    "        self.conv = nn.ConvTranspose3d(dim_in, dim_out, 4, 2, 1) if d3 else nn.ConvTranspose2d(dim_in, dim_out, 4, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out=None, stride=2,  d3 = False):\n",
    "        super().__init__()\n",
    "        if dim_out is None:\n",
    "            dim_out = dim_in\n",
    "        self.conv = nn.Conv3d(dim_in, dim_out, 3, stride, 1) if d3 else nn.Conv2d(dim_in, dim_out, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim, d3=False, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        shape = (1, dim, 1, 1, 1) if d3 else (1, dim, 1, 1) \n",
    "        self.g = nn.Parameter(torch.ones(*shape))\n",
    "        self.b = nn.Parameter(torch.zeros(*shape))\n",
    "\n",
    "    def forward(self, x):\n",
    "        var = torch.var(x, dim=1, unbiased=False, keepdim=True)\n",
    "        mean = torch.mean(x, dim=1, keepdim=True)\n",
    "        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b\n",
    "\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)\n",
    "\n",
    "\n",
    "# building block modules\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, large_filter=False, d3=False):\n",
    "        super().__init__()\n",
    "        conv_layer = nn.Conv3d if d3 else nn.Conv2d\n",
    "        self.block = nn.Sequential(\n",
    "            conv_layer(dim, dim_out, 7 if large_filter else 3, padding=3 if large_filter else 1), \n",
    "            LayerNorm(dim_out, d3=d3), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dim_out, time_emb_dim=None, large_filter=False, d3=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        conv_layer = nn.Conv3d if d3 else nn.Conv2d\n",
    "        \n",
    "        self.mlp = (\n",
    "            nn.Sequential(nn.LeakyReLU(0.2), nn.Linear(time_emb_dim, dim_out))\n",
    "            if exists(time_emb_dim)\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, large_filter, d3=d3)\n",
    "        self.block2 = Block(dim_out, dim_out, d3=d3)\n",
    "        self.res_conv = conv_layer(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb=None):\n",
    "        h = self.block1(x)\n",
    "\n",
    "        if exists(time_emb):\n",
    "            h = h + self.mlp(time_emb)[:, :, None, None]\n",
    "\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, dim, heads=1, dim_head=None):\n",
    "        super().__init__()\n",
    "        if dim_head is None:\n",
    "            dim_head = dim\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
    "        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
    "        q, k, v = map(lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv)\n",
    "        q = q * self.scale\n",
    "\n",
    "        k = k.softmax(dim=-1)\n",
    "        context = torch.einsum(\"b h d n, b h e n -> b h d e\", k, v)\n",
    "\n",
    "        out = torch.einsum(\"b h d e, b h d n -> b h e n\", context, q)\n",
    "        out = rearrange(out, \"b h c (x y) -> b (h c) x y\", h=self.heads, x=h, y=w)\n",
    "        return self.to_out(out)\n",
    "\n",
    "\n",
    "class LearnedSinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        assert (dim % 2) == 0\n",
    "        half_dim = dim // 2\n",
    "        self.weights = nn.Parameter(torch.randn(half_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = rearrange(x, 'b -> b 1')\n",
    "        freqs = x * rearrange(self.weights, 'd -> 1 d') * 2 * math.pi\n",
    "        fouriered = torch.cat((freqs.sin(), freqs.cos()), dim = -1)\n",
    "        fouriered = torch.cat((x, fouriered), dim = -1)\n",
    "        return fouriered\n",
    "\n",
    "class ImprovedSinusoidalPosEmb(nn.Module):\n",
    "    \"\"\" following @crowsonkb 's lead with random (learned optional) sinusoidal pos emb \"\"\"\n",
    "    \"\"\" https://github.com/crowsonkb/v-diffusion-jax/blob/master/diffusion/models/danbooru_128.py#L8 \"\"\"\n",
    "\n",
    "    def __init__(self, dim, is_random = False):\n",
    "        super().__init__()\n",
    "        assert (dim % 2) == 0\n",
    "        half_dim = dim // 2\n",
    "        self.weights = nn.Parameter(torch.randn(half_dim), requires_grad = not is_random)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = rearrange(x, 'b -> b 1')\n",
    "        freqs = x * rearrange(self.weights, 'd -> 1 d') * 2 * math.pi\n",
    "        fouriered = torch.cat((freqs.sin(), freqs.cos()), dim = -1)\n",
    "        fouriered = torch.cat((x, fouriered), dim = -1)\n",
    "        return fouriered\n",
    "\n",
    "\n",
    "class VBRCondition(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.scale = nn.Conv2d(input_dim, output_dim, 1)\n",
    "        self.shift = nn.Conv2d(input_dim, output_dim, 1)\n",
    "\n",
    "    def forward(self, input, cond):\n",
    "        cond = cond.reshape(-1, 1, 1, 1)\n",
    "        scale = self.scale(cond)\n",
    "        shift = self.shift(cond)\n",
    "        return input * scale + shift\n",
    "\n",
    "\n",
    "class GDN(nn.Module):\n",
    "    \"\"\"Generalized divisive normalization layer.\n",
    "    y[i] = x[i] / sqrt(beta[i] + sum_j(gamma[j, i] * x[j]))\n",
    "    \"\"\"\n",
    "    def __init__(self, ch, inverse=False, beta_min=1e-6, gamma_init=.1, reparam_offset=2**-18):\n",
    "        super(GDN, self).__init__()\n",
    "        self.inverse = inverse\n",
    "        self.beta_min = beta_min\n",
    "        self.gamma_init = gamma_init\n",
    "        self.reparam_offset = reparam_offset\n",
    "\n",
    "        self.build(ch)\n",
    "\n",
    "    def build(self, ch):\n",
    "        self.pedestal = self.reparam_offset**2\n",
    "        self.beta_bound = (self.beta_min + self.reparam_offset**2)**.5\n",
    "        self.gamma_bound = self.reparam_offset\n",
    "\n",
    "        # Create beta param\n",
    "        beta = torch.sqrt(torch.ones(ch) + self.pedestal)\n",
    "        self.beta = nn.Parameter(beta)\n",
    "\n",
    "        # Create gamma param\n",
    "        eye = torch.eye(ch)\n",
    "        g = self.gamma_init * eye\n",
    "        g = g + self.pedestal\n",
    "        gamma = torch.sqrt(g)\n",
    "\n",
    "        self.gamma = nn.Parameter(gamma)\n",
    "        self.pedestal = self.pedestal\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        unfold = False\n",
    "        if inputs.dim() == 5:\n",
    "            unfold = True\n",
    "            bs, ch, d, w, h = inputs.size()\n",
    "            inputs = inputs.view(bs, ch, d * w, h)\n",
    "\n",
    "        _, ch, _, _ = inputs.size()\n",
    "\n",
    "        # Beta bound and reparam\n",
    "        beta = LowerBound.apply(self.beta, self.beta_bound)\n",
    "        beta = beta**2 - self.pedestal\n",
    "\n",
    "        # Gamma bound and reparam\n",
    "        gamma = LowerBound.apply(self.gamma, self.gamma_bound)\n",
    "        gamma = gamma**2 - self.pedestal\n",
    "        gamma = gamma.view(ch, ch, 1, 1)\n",
    "\n",
    "        # Norm pool calc\n",
    "        norm_ = nn.functional.conv2d(inputs**2, gamma, beta)\n",
    "        norm_ = torch.sqrt(norm_)\n",
    "\n",
    "        # Apply norm\n",
    "        if self.inverse:\n",
    "            outputs = inputs * norm_\n",
    "        else:\n",
    "            outputs = inputs / norm_\n",
    "\n",
    "        if unfold:\n",
    "            outputs = outputs.view(bs, ch, d, w, h)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class GDN1(GDN):\n",
    "    def forward(self, inputs):\n",
    "        unfold = False\n",
    "        if inputs.dim() == 5:\n",
    "            unfold = True\n",
    "            bs, ch, d, w, h = inputs.size()\n",
    "            inputs = inputs.view(bs, ch, d * w, h)\n",
    "\n",
    "        _, ch, _, _ = inputs.size()\n",
    "\n",
    "        # Beta bound and reparam\n",
    "        beta = LowerBound.apply(self.beta, self.beta_bound)\n",
    "        beta = beta ** 2 - self.pedestal\n",
    "\n",
    "        # Gamma bound and reparam\n",
    "        gamma = LowerBound.apply(self.gamma, self.gamma_bound)\n",
    "        gamma = gamma ** 2 - self.pedestal\n",
    "        gamma = gamma.view(ch, ch, 1, 1)\n",
    "\n",
    "        # Norm pool calc\n",
    "        norm_ = nn.functional.conv2d(torch.abs(inputs), gamma, beta)\n",
    "        # norm_ = torch.sqrt(norm_)\n",
    "\n",
    "        # Apply norm\n",
    "        if self.inverse:\n",
    "            outputs = inputs * norm_\n",
    "        else:\n",
    "            outputs = inputs / norm_\n",
    "\n",
    "        if unfold:\n",
    "            outputs = outputs.view(bs, ch, d, w, h)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class PriorFunction(nn.Module):\n",
    "    #  A Custom Function described in Balle et al 2018. https://arxiv.org/pdf/1802.01436.pdf\n",
    "    __constants__ = ['bias', 'in_features', 'out_features']\n",
    "\n",
    "    def __init__(self, parallel_dims, in_features, out_features, scale, bias=True):\n",
    "        super(PriorFunction, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(parallel_dims, 1, 1, in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(parallel_dims, 1, 1, 1, out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters(scale)\n",
    "\n",
    "    def reset_parameters(self, scale):\n",
    "        nn.init.constant_(self.weight, scale)\n",
    "        if self.bias is not None:\n",
    "            nn.init.uniform_(self.bias, -0.5, 0.5)\n",
    "\n",
    "    def forward(self, input, detach=False):\n",
    "        # input shape (channel, batch_size, in_features)\n",
    "        if detach:\n",
    "            return torch.matmul(input, F.softplus(self.weight.detach())) + self.bias.detach()\n",
    "        return torch.matmul(input, F.softplus(self.weight)) + self.bias\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(self.in_features, self.out_features, self.bias\n",
    "                                                                 is not None)\n",
    "\n",
    "\n",
    "class FlexiblePrior(nn.Module):\n",
    "    '''\n",
    "        A prior model described in Balle et al 2018 Appendix 6.1 https://arxiv.org/pdf/1802.01436.pdf\n",
    "        return the boxshape likelihood\n",
    "    '''\n",
    "    def __init__(self, channels=256, dims=[3, 3, 3], init_scale=10.):\n",
    "        super(FlexiblePrior, self).__init__()\n",
    "        dims = [1] + dims + [1]\n",
    "        self.chain_len = len(dims) - 1\n",
    "        scale = init_scale**(1 / self.chain_len)\n",
    "        h_b = []\n",
    "        for i in range(self.chain_len):\n",
    "            init = np.log(np.expm1(1 / scale / dims[i + 1]))\n",
    "            h_b.append(PriorFunction(channels, dims[i], dims[i + 1], init))\n",
    "        self.affine = nn.ModuleList(h_b)\n",
    "        self.a = nn.ParameterList(\n",
    "            [nn.Parameter(torch.zeros(channels, 1, 1, 1, dims[i + 1])) for i in range(self.chain_len - 1)])\n",
    "\n",
    "        # optimize the medians to fix the offset issue\n",
    "        self._medians = nn.Parameter(torch.zeros(1, channels, 1, 1))\n",
    "        # self.register_buffer('_medians', torch.zeros(1, channels, 1, 1))\n",
    "\n",
    "    @property\n",
    "    def medians(self):\n",
    "        return self._medians.detach()\n",
    "\n",
    "    def cdf(self, x, logits=True, detach=False):\n",
    "        x = x.transpose(0, 1).unsqueeze(-1)  # C, N, H, W, 1\n",
    "        if detach:\n",
    "            for i in range(self.chain_len - 1):\n",
    "                x = self.affine[i](x, detach)\n",
    "                x = x + torch.tanh(self.a[i].detach()) * torch.tanh(x)\n",
    "            if logits:\n",
    "                return self.affine[-1](x, detach).squeeze(-1).transpose(0, 1)\n",
    "            return torch.sigmoid(self.affine[-1](x, detach)).squeeze(-1).transpose(0, 1)\n",
    "\n",
    "        # not detached\n",
    "        for i in range(self.chain_len - 1):\n",
    "            x = self.affine[i](x)\n",
    "            x = x + torch.tanh(self.a[i]) * torch.tanh(x)\n",
    "        if logits:\n",
    "            return self.affine[-1](x).squeeze(-1).transpose(0, 1)\n",
    "        return torch.sigmoid(self.affine[-1](x)).squeeze(-1).transpose(0, 1)\n",
    "\n",
    "    def pdf(self, x):\n",
    "        cdf = self.cdf(x, False)\n",
    "        jac = torch.ones_like(cdf)\n",
    "        pdf = torch.autograd.grad(cdf, x, grad_outputs=jac)[0]\n",
    "        return pdf\n",
    "\n",
    "    def get_extraloss(self):\n",
    "        target = 0\n",
    "        logits = self.cdf(self._medians, detach=True)\n",
    "        extra_loss = torch.abs(logits - target).sum()\n",
    "        return extra_loss\n",
    "\n",
    "    def likelihood(self, x, min=1e-9):\n",
    "        lower = self.cdf(x - 0.5, True)\n",
    "        upper = self.cdf(x + 0.5, True)\n",
    "        sign = -torch.sign(lower + upper).detach()\n",
    "        upper = torch.sigmoid(upper * sign)\n",
    "        lower = torch.sigmoid(lower * sign)\n",
    "        return LowerBound.apply(torch.abs(upper - lower), min)\n",
    "\n",
    "    def icdf(self, xi, method='bisection', max_iterations=1000, tol=1e-9, **kwargs):\n",
    "        if method == 'bisection':\n",
    "            init_interval = [-1, 1]\n",
    "            left_endpoints = torch.ones_like(xi) * init_interval[0]\n",
    "            right_endpoints = torch.ones_like(xi) * init_interval[1]\n",
    "\n",
    "            def f(z):\n",
    "                return self.cdf(z, logits=False, detach=True) - xi\n",
    "\n",
    "            while True:\n",
    "                if (f(left_endpoints) < 0).all():\n",
    "                    break\n",
    "                else:\n",
    "                    left_endpoints = left_endpoints * 2\n",
    "            while True:\n",
    "                if (f(right_endpoints) > 0).all():\n",
    "                    break\n",
    "                else:\n",
    "                    right_endpoints = right_endpoints * 2\n",
    "\n",
    "            for i in range(max_iterations):\n",
    "                mid_pts = 0.5 * (left_endpoints + right_endpoints)\n",
    "                mid_vals = f(mid_pts)\n",
    "                pos = mid_vals > 0\n",
    "                non_pos = torch.logical_not(pos)\n",
    "                neg = mid_vals < 0\n",
    "                non_neg = torch.logical_not(neg)\n",
    "                left_endpoints = left_endpoints * non_neg.float() + mid_pts * neg.float()\n",
    "                right_endpoints = right_endpoints * non_pos.float() + mid_pts * pos.float()\n",
    "                if (torch.logical_and(non_pos, non_neg)).all() or torch.min(right_endpoints - left_endpoints) <= tol:\n",
    "                    print(f'bisection terminated after {i} its')\n",
    "                    break\n",
    "\n",
    "            return mid_pts\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def sample(self, img, shape):\n",
    "        uni = torch.rand(shape, device=img.device)\n",
    "        return self.icdf(uni)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bcac7be-c320-4f77-b19b-d98bddc9d805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ChannelShuffle(nn.Module):\n",
    "    def __init__(self, scale_factor = 2):\n",
    "        super().__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "\n",
    "        batch_size, channels, *in_dims = inputs.size()\n",
    "        # in_depth, in_height, in_width = dims\n",
    "        channels //= self.scale_factor ** len(in_dims)\n",
    "        \n",
    "        out_dims = [dim * self.scale_factor for dim in in_dims]\n",
    "        print(out_dims)\n",
    "        \n",
    "        if len(in_dims)==3:\n",
    "            input_view = inputs.contiguous().view(batch_size, channels, self.scale_factor, self.scale_factor, self.scale_factor, *in_dims)\n",
    "            shuffle_out = input_view.permute(0, 1, 5, 2, 6, 3, 7, 4).contiguous()\n",
    "        else:                                         #  0      1          2                    3                  4       5\n",
    "            input_view = inputs.contiguous().view(batch_size, channels, self.scale_factor, self.scale_factor,  *in_dims)\n",
    "            shuffle_out = input_view.permute(0, 1, 4, 2, 5, 3).contiguous()\n",
    "\n",
    "        return shuffle_out.view(batch_size, channels, *out_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7f55702-a416-49a1-9e6a-3356c986b34c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 60, 60]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2, 60, 60, 60])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data  = torch.randn(10,16,30,30,30)\n",
    "\n",
    "model = ChannelShuffle()\n",
    "\n",
    "model(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a00b1f46-ef4b-42b8-b674-fea1881116ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compressor(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim=64,\n",
    "        dim_mults=(1, 2, 3, 4),\n",
    "        reverse_dim_mults=(4, 3, 2, 1),\n",
    "        hyper_dims_mults=(4, 4, 4),\n",
    "        channels=3,\n",
    "        out_channels=3,\n",
    "        d3 = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.dims = [channels, *map(lambda m: dim * m, dim_mults)]\n",
    "        self.in_out = list(zip(self.dims[:-1], self.dims[1:]))\n",
    "        \n",
    "        self.reversed_dims = [*map(lambda m: dim * m, reverse_dim_mults), out_channels]\n",
    "        self.reversed_in_out = list(zip(self.reversed_dims[:-1], self.reversed_dims[1:]))\n",
    "        \n",
    "        assert self.dims[-1] == self.reversed_dims[0]\n",
    "        self.hyper_dims = [self.dims[-1], *map(lambda m: dim * m, hyper_dims_mults)]\n",
    "        self.hyper_in_out = list(zip(self.hyper_dims[:-1], self.hyper_dims[1:]))\n",
    "        self.reversed_hyper_dims = list(\n",
    "            reversed([self.dims[-1] * 2, *map(lambda m: dim * m, hyper_dims_mults)])\n",
    "        )\n",
    "        self.reversed_hyper_in_out = list(\n",
    "            zip(self.reversed_hyper_dims[:-1], self.reversed_hyper_dims[1:])\n",
    "        )\n",
    "        self.prior = FlexiblePrior(self.hyper_dims[-1])\n",
    "\n",
    "    def get_extra_loss(self):\n",
    "        return self.prior.get_extraloss()\n",
    "\n",
    "    def build_network(self):\n",
    "        self.enc = nn.ModuleList([])\n",
    "        self.dec = nn.ModuleList([])\n",
    "        self.hyper_enc = nn.ModuleList([])\n",
    "        self.hyper_dec = nn.ModuleList([])\n",
    "\n",
    "    def encode(self, input):\n",
    "        \n",
    "        self.t_dim = input.shape[2]\n",
    "        \n",
    "        for i, (resnet, down) in enumerate(self.enc): # [b, 1, t, 256, 256]\n",
    "            if i==0:\n",
    "                input = input.permute(0,2,1,3,4)\n",
    "                input = input.reshape(-1, *input.shape[2:]) # [b*t, 1, 256, 256]\n",
    "            if i==2:\n",
    "                input = input.reshape(-1, self.t_dim, *input.shape[1:])\n",
    "                input = input.permute(0,2,1,3,4) # [b, c, t, h, w]\n",
    "                \n",
    "            input = resnet(input)\n",
    "            input = down(input)\n",
    "            \n",
    "\n",
    "        input = input.permute(0,2,1,3,4)\n",
    "        input = input.reshape(-1, *input.shape[2:])\n",
    "        \n",
    "            \n",
    "        latent = input\n",
    "        for i, (conv, act) in enumerate(self.hyper_enc):\n",
    "            input = conv(input)\n",
    "            input = act(input)\n",
    "            \n",
    "        hyper_latent = input\n",
    "        q_hyper_latent = quantize(hyper_latent, \"dequantize\", self.prior.medians)\n",
    "        input = q_hyper_latent\n",
    "        for i, (deconv, act) in enumerate(self.hyper_dec):\n",
    "            input = deconv(input)\n",
    "            input = act(input)\n",
    "\n",
    "        mean, scale = input.chunk(2, 1)\n",
    "        latent_distribution = NormalDistribution(mean, scale.clamp(min=0.1))\n",
    "        q_latent = quantize(latent, \"dequantize\", latent_distribution.mean)\n",
    "        state4bpp = {\n",
    "            \"latent\": latent,\n",
    "            \"hyper_latent\": hyper_latent,\n",
    "            \"latent_distribution\": latent_distribution,\n",
    "        }\n",
    "        return q_latent, q_hyper_latent, state4bpp\n",
    "    \n",
    "    def decode(self, input): # [n*t, c, h,w ] [8, 256, 16, 16]\n",
    "        # output = []\n",
    "        \n",
    "        for i, (resnet, up) in enumerate(self.dec):\n",
    "            if i==2:\n",
    "                input = input.permute(0,2,1,3,4)\n",
    "                input = input.reshape(-1, *input.shape[2:]) # [b*t, 1, 256, 256]\n",
    "            if i==0:\n",
    "                input = input.reshape(-1, self.t_dim//4, *input.shape[1:])\n",
    "                input = input.permute(0,2,1,3,4) # [b, c, t, h, w]\n",
    "                \n",
    "            input = resnet(input)\n",
    "            input = up(input)\n",
    "        \n",
    "        input = input.reshape(-1, self.t_dim, *input.shape[1:])\n",
    "        input = input.permute(0,2,1,3,4)\n",
    "        \n",
    "        return input\n",
    "\n",
    "    def bpp(self, shape, state4bpp):\n",
    "        B, H, W = shape[0], shape[-2], shape[-1]\n",
    "        n_pixels = shape[-3] * shape[-2] * shape[-1]\n",
    "        \n",
    "        latent = state4bpp[\"latent\"]\n",
    "        hyper_latent = state4bpp[\"hyper_latent\"]\n",
    "        latent_distribution = state4bpp[\"latent_distribution\"]\n",
    "        if self.training:\n",
    "            q_hyper_latent = quantize(hyper_latent, \"noise\")\n",
    "            q_latent = quantize(latent, \"noise\")\n",
    "        else:\n",
    "            q_hyper_latent = quantize(hyper_latent, \"dequantize\", self.prior.medians)\n",
    "            q_latent = quantize(latent, \"dequantize\", latent_distribution.mean)\n",
    "        hyper_rate = -self.prior.likelihood(q_hyper_latent).log2()\n",
    "        cond_rate = -latent_distribution.likelihood(q_latent).log2()\n",
    "        bpp = (hyper_rate.reshape(B, -1).sum(dim=-1) + cond_rate.reshape(B, -1).sum(dim=-1)) / n_pixels\n",
    "        return bpp\n",
    "\n",
    "    def forward(self, input):\n",
    "        q_latent, q_hyper_latent, state4bpp = self.encode(input)\n",
    "        bpp = self.bpp(input.shape, state4bpp)\n",
    "        output = self.decode(q_latent)\n",
    "        return {\n",
    "            \"output\": output,\n",
    "            \"bpp\": bpp,\n",
    "            \"q_latent\": q_latent,\n",
    "            \"q_hyper_latent\": q_hyper_latent,\n",
    "        }\n",
    "\n",
    "\n",
    "class ResnetCompressor(Compressor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim=64,\n",
    "        dim_mults=(1, 2, 3, 4),\n",
    "        reverse_dim_mults=(4, 3, 2, 1),\n",
    "        hyper_dims_mults=(4, 4, 4),\n",
    "        channels=3,\n",
    "        out_channels=3,\n",
    "        d3 = False\n",
    "    ):\n",
    "        super().__init__(\n",
    "            dim,\n",
    "            dim_mults,\n",
    "            reverse_dim_mults,\n",
    "            hyper_dims_mults,\n",
    "            channels,\n",
    "            out_channels,\n",
    "            d3\n",
    "        )\n",
    "        self.d3 = d3\n",
    "        self.conv_layer =  nn.Conv3d if d3 else nn.Conv2d\n",
    "        self.deconv_layer = nn.ConvTranspose3d if d3 else nn.ConvTranspose2d\n",
    "        \n",
    "        self.build_network()\n",
    "        \n",
    "\n",
    "    def build_network(self):\n",
    "\n",
    "        self.enc = nn.ModuleList([])\n",
    "        self.dec = nn.ModuleList([])\n",
    "        self.hyper_enc = nn.ModuleList([])\n",
    "        self.hyper_dec = nn.ModuleList([])\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(self.in_out):\n",
    "            is_last = ind >= (len(self.in_out) - 1)\n",
    "            d3 = self.d3 if ind>=2 else False\n",
    "            self.enc.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        ResnetBlock(dim_in, dim_out, None, True if ind == 0 else False, d3 = d3),\n",
    "                        Downsample(dim_out, d3 = d3),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(self.reversed_in_out):\n",
    "            is_last = ind >= (len(self.reversed_in_out) - 1)\n",
    "            d3 = self.d3 if ind<2 else False\n",
    "            self.dec.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        ResnetBlock(dim_in, dim_out if not is_last else dim_in, d3 = d3),\n",
    "                        Upsample(dim_out if not is_last else dim_in, dim_out, d3 = d3),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(self.hyper_in_out):\n",
    "            is_last = ind >= (len(self.hyper_in_out) - 1)\n",
    "            self.hyper_enc.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        nn.Conv2d(dim_in, dim_out, 3, 1, 1) if ind == 0 else nn.Conv2d(dim_in, dim_out, 5, 2, 2),\n",
    "                        nn.LeakyReLU(0.2) if not is_last else nn.Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(self.reversed_hyper_in_out):\n",
    "            is_last = ind >= (len(self.reversed_hyper_in_out) - 1)\n",
    "            self.hyper_dec.append(\n",
    "                nn.ModuleList(\n",
    "                    [\n",
    "                        nn.Conv2d(dim_in, dim_out, 3, 1, 1) if is_last else nn.ConvTranspose2d(dim_in, dim_out, 5, 2, 2, 1),\n",
    "                        nn.LeakyReLU(0.2) if not is_last else nn.Identity(),\n",
    "                    ]\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0f682de-d628-4c9c-9eb6-0f314fae10c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ResnetCompressor(d3=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1324d9ed-e7f8-44cc-a9ca-97f08e14efe8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding torch.Size([32, 64, 128, 128])\n",
      "encoding torch.Size([32, 128, 64, 64])\n",
      "encoding torch.Size([2, 192, 8, 32, 32])\n",
      "encoding torch.Size([2, 256, 4, 16, 16])\n",
      "hyper torch.Size([8, 256, 16, 16])\n",
      "decoding torch.Size([8, 256, 16, 16])\n",
      "decoding torch.Size([2, 256, 4, 16, 16])\n",
      "decoding torch.Size([2, 192, 8, 32, 32])\n",
      "decoding torch.Size([32, 128, 64, 64])\n",
      "decoding torch.Size([32, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    result = model(torch.randn(2,3,16,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37b3404d-61d1-43f5-a5fd-0dcdbbe07828",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 16, 256, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['output'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5576337e-c3ed-4f56-b828-a18af2c96fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6fa5b6f-638c-4cdf-aafd-095034352e11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/blue/ranka/xiao.li/DiffusionModel/models/CDC/compress_modules3d.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnetwork_components\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResnetBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlexiblePrior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDownsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUpsample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/48172898/ipykernel_1919969/3382094314.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcompress_modules3d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResnetCompressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResnetCompressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcount_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/blue/ranka/xiao.li/DiffusionModel/models/CDC/compress_modules3d.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnetwork_components\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResnetBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlexiblePrior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDownsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUpsample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mnetwork_components\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResnetBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlexiblePrior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDownsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUpsample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/blue/ranka/xiao.li/DiffusionModel/models/CDC/network_components.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLowerBound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meinops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from compress_modules3d import ResnetCompressor\n",
    "model = ResnetCompressor(d3=True)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987e8504-9299-432f-a4cf-fe54063ce222",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/49560576/ipykernel_716499/3395109225.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcompress_modules3d_mid_SR\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResnetCompressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/blue/ranka/xiao.li/DiffusionModel/models/CDC/compress_modules3d_mid_SR.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnetwork_components\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResnetBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlexiblePrior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDownsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUpsample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquantize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormalDistribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c22e5-661b-45bf-8d3e-f0e1cb6c9bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResnetCompressor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8.1",
   "language": "python",
   "name": "pytorch-1.8.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
